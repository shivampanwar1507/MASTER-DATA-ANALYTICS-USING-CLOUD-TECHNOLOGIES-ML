use "DATA_PIPELINING";

--Step 1: Create the table

CREATE OR REPLACE TABLE HEALTHCARE(
Patientid VARCHAR(15),	
gender CHAR(8),	
age VARCHAR(5)	,
hypertension CHAR(20),	
heart_disease CHAR(20),	
ever_married CHAR(30),	
work_type VARCHAR(60),	
Residence_type CHAR(30)	,
avg_glucose_level VARCHAR(20),	
bmi VARCHAR(20)	,
smoking_status	VARCHAR(20),
stroke CHAR(20)
);

-- Step 2: Create a policy using json and in resource update the bucket arn in json text.
-- Step 3: Create a role and attach that policy to it.
-- Step 4: Update the role_arn and bucket location then create the storage integration. 

CREATE OR REPLACE STORAGE integration s3_storage_int
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = S3
ENABLED = TRUE
STORAGE_AWS_ROLE_ARN ='arn:aws:iam::143250224569:role/healthcare-role'
STORAGE_ALLOWED_LOCATIONS =('s3://healthcare-bucket-1/');

-- Step 5: Describe storage integration i.e. run the below statement.

desc integration s3_storage_int;

-- Step 6: Go to role in aws then trust relationship and update the aws tag in it by coping the "STORAGE_AWS_IAM_USER_ARN" in that tag.
-- Step 7: If we are creating with external id same go with external id too.(Paste it in the place given)
-- Step 8: Update the role and after that create the stage.

CREATE OR REPLACE STAGE HEALTHCARE_Stage
URL ='s3://healthcare-bucket-1'
-- credential not required
--credentials=(aws_key_id='AKIAXQKR3H3PSG72XFMK'aws_secret_key='eKL6a6FjlQHic4s8Ne712Aelzg2ou4j6tNsVvFq5')
file_format=CSV
storage_integration = s3_storage_int;

LIST @HEALTHCARE_SP;

-- Step 9: show stages.
SHOW STAGES;

-- Step 10: Create the pipe.
--CREATE SNOWPIPE THAT RECOGNISES CSV THAT ARE INGESTED FROM EXTERNAL STAGE AND COPIES THE DATA INTO PATIENTS TABLE
--The AUTO_INGEST=true parameter specifies to read event notifications sent from an S3 bucket to an SQS queue when new data is ready to load.


CREATE OR REPLACE PIPE HEALTHCARE_SNOWPIPE AUTO_INGEST = TRUE AS
COPY INTO "DATA_PIPELINING"."PUBLIC"."HEALTHCARE"
FROM @HEALTHCARE_Stage
FILE_FORMAT = CSV;

-- Step 11: show pipe.
SHOW PIPES;

-- Step 12: Copy the notification channel and go to bucket -->properties-->event notification-->create event and paste it in last text box and create the event.

-- Step 13: Run the alter pipe statement to see what is in the pipe. It should be blank as we have not uploaded any file in the bucket.
-- Step 14: If it comes blank i.e. everything is right till now. Also check the status it represent if any file is pending from bucket into pipe.
-- Step 15: Upload the csv file in the bucket and run this statement again, it should show the file details.
alter pipe HEALTHCARE_SNOWPIPE refresh;
SELECT SYSTEM$PIPE_STATUS('HEALTHCARE_SNOWPIPE');

-- Step 16: after alter pipe showing file sent, run the count statement.


SELECT count(*) FROM HEALTHCARE;

--Step 17: The records of file are showing in the table of snowflake.
select * from HEALTHCARE;